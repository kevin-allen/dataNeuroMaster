{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5, Data science in Neuroscience\n",
    "\n",
    "\n",
    "## Plan for today\n",
    "\n",
    "1. Review key machine learning concepts\n",
    "2. Review of last week's exercise: Using a machine learning approach to find the best parameters for a head-direction cell.\n",
    "3. Introduction to deep neuronal networks\n",
    "4. Pose estimation using Deeplabcut\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning briefly\n",
    "\n",
    "* This gives computer the ability to learn without being explicitely programmed (Arthur Samuel, 1959).\n",
    "\n",
    "## Types\n",
    "\n",
    "* Prediction versus inference\n",
    "* Supervised versus unsupervised\n",
    "* Regression versus classification\n",
    "\n",
    "These concepts are useful to quickly find the right tool (model) for the job.\n",
    "\n",
    "## How do computers learn?\n",
    "\n",
    "Often using an iterative process (i.e. a loop).\n",
    "\n",
    "1. Feed data to your model\n",
    "2. Calculate the error (loss).\n",
    "3. Adjust the model parameters by a small amount to minimize the loss, using gradients.\n",
    "4. Go back to 1 until the gradients are near 0.\n",
    "\n",
    "\n",
    "## Our linear regression model\n",
    "\n",
    "* One of the simplest models.\n",
    "* $Y = wX + b$\n",
    "* $Y$: target\n",
    "* $X$: features (inputs)\n",
    "* $w$ is the slope and $b$ is the intercept.\n",
    "* We found the best parameters ($w$ and $b$) that minimize a loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Back to our exercise at the end o Lecture 4\n",
    "\n",
    "Can you find the best parameters to explain the firing rate of a head direction cell?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "## Deep neural networks\n",
    "\n",
    "* Mathematical entities capable of representing complicated functions through a composition of simpler functions.\n",
    "* Deep neural network have **multiple layers** between the input and output layers. \n",
    "* New data comes from the left, and calculations propagates towards the ouput layer.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/deep-neural-network.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial neuron\n",
    "\n",
    "A **neuron** is the building block of the neural network.\n",
    "\n",
    "\n",
    "They do 3 things: \n",
    "* A linear transofrmation of the inputs\n",
    "* Adding a constant \n",
    "* Applying a fixed nonlinear function (activation fucntion)\n",
    "    \n",
    "The input can be a single value or a vector. The output can be a single value or a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neurons are not too complicated. We can easily code one to understand how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printInputWeightBias(inputData,w,b):\n",
    "    \"\"\"\n",
    "    Function to print the shape and data in inputData, weights and biases\n",
    "    \"\"\"\n",
    "    print(\"************\")\n",
    "    print(\"inputData.shape:\",inputData.shape)\n",
    "    print(\"inputData:\",inputData)\n",
    "    print(\"************\")\n",
    "    print(\"weights.shape:\", w.shape)\n",
    "    print(\"weights:\",w)\n",
    "    print(\"************\")\n",
    "    print(\"bias.shape\", b.shape)\n",
    "    print(\"bias:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare some input data, weights (w) and bias (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "inputData.shape: (1, 15)\n",
      "inputData: [[-1.         -0.85714286 -0.71428571 -0.57142857 -0.42857143 -0.28571429\n",
      "  -0.14285714  0.          0.14285714  0.28571429  0.42857143  0.57142857\n",
      "   0.71428571  0.85714286  1.        ]]\n",
      "************\n",
      "weights.shape: (15, 1)\n",
      "weights: [[ 0.26535208]\n",
      " [ 0.28919833]\n",
      " [-0.05897398]\n",
      " [-0.00632948]\n",
      " [-0.11905716]\n",
      " [ 0.25547774]\n",
      " [-0.23994615]\n",
      " [ 0.48673328]\n",
      " [ 0.41926392]\n",
      " [-0.30670968]\n",
      " [ 0.22970875]\n",
      " [-0.40350481]\n",
      " [-0.29645525]\n",
      " [-0.38741412]\n",
      " [-0.44955527]]\n",
      "************\n",
      "bias.shape (1,)\n",
      "bias: [0.510774]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inputSize=15\n",
    "inputData = np.linspace(-1,1,inputSize).reshape(-1,inputSize) # 1D array as input\n",
    "w = np.random.random(inputSize).reshape(inputSize,-1)-0.5 # numbers weights between -0.5 and 0.5, 1D array matching the size of input\n",
    "b = np.random.random(1) # a bias term \n",
    "\n",
    "printInputWeightBias(inputData,w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a simple function to represent the calculation of a neuron. The formula is very similar to a regression model, with the addition of a non-linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_function(inputData,w,b):\n",
    "    \"\"\"\n",
    "    Operation performed by a single neuron\n",
    "    \n",
    "    inputData@w is the dot product of 2 matrices.\n",
    "    \"\"\"\n",
    "    return np.tanh(inputData@w + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.799655]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_function(inputData,w,b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main role of the np.tanh function is to add some non-linearity in the network. Instead of having a straight line, we get a s-shaped curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3hddZ3v8fcnaZPeS9OWtrSlFyilCFo1FvECjgIix6GOg1o9zhQvD3PDM47HGeHwPOoD4zk4F2FmjjPaARQvA6ijY0frQS5adLjYoFBK0zZJW6ExbXdLaS69pEm+54+9ApuYtDuXvdfeyef1PPvZa/3Wb639zepuvlnr91u/nyICMzOzwapIOwAzMytPTiBmZjYkTiBmZjYkTiBmZjYkTiBmZjYk49IOoJhmzZoVixcvTjsMM7Oy8sQTTxyIiNl9y8dUAlm8eDF1dXVph2FmVlYk/bq/ct/CMjOzIXECMTOzIXECMTOzIXECMTOzIXECMTOzIUk1gUi6U9J+SVsG2C5J/yipUdJmSa/J2bZWUkPyWlu8qM3MDNK/AvkqcMVJtr8DWJa8rgX+BUBSDfAZ4EJgFfAZSTMKGqmZmb1Mqs+BRMTDkhafpMpq4GuRHXP+MUmnSZoHvAW4PyKeB5B0P9lEdHdhIzazXhFBR2c37ce6OHqim6Od3Rw90c2xZLmzu4eunqAree9Olrt7gp6Anggiee9d7z1u9h0ieQcIXirPro/oDzOSRytJa9+wmJlTqkf0mKX+IOF84Lmc9T1J2UDlv0XStWSvXjjzzDMLE6XZKBQRPPf8UZ5uPkx9Syv7245xoL2Tg+3HOdDeyYH24xzv6kk7zBEjpR1BYV21cv6YSyDDFhHrgHUAtbW1o//PDLMhajt2goe27WdL82G2NLey5TeHaTvWBUBlhZg1pYpZU6qZOaWas2ZPYdbUamomVzFtwngmVlUwcXwlE8ZXMnF8JROrKqkaV8G4igrGVYjKCjG+soLKZLlSQhVQIVGh7Dtkf4kLvfjLXIAken+3v1g+2n/bl4lSTyDNwMKc9QVJWTPZ21i55T8tWlRmo8ivD3bw1Ud28+26PbQf76JqXAUr5k3jqledwfnzp3P+GdM5Z+4UqsdVph2qlZhSTyDrgesk3UO2wfxwRLRIug/43zkN55cDN6QVpFm5iQgebTrInf+1iwe37WdchfhvF8zjDy5azCsXTGd8Zdr9a6wcpJpAJN1N9kpilqQ9ZHtWjQeIiC8BG4ArgUbgCPChZNvzkm4GNiWHuqm3Qd3MTu7nDQe4+Qdb2b6vjZmTq/jY75zNB1+/iNOnTUg7NCszijHQ+6BXbW1teDReG8t+uLmFj9/7KxbOmMQfv+UsrnrVGUwY71tTdnKSnoiI2r7lpX4Ly8xGyLc2Pcf1393MaxfN4I5rXse0CePTDsnKnBOI2Rhwx893cfMPtnLxObP58gdfy8QqX3XY8DmBmI1iEcE/PNjAbQ808I7z53LbmpXuTWUjxgnEbJSKCP76h/Xc8fNdXP3aBdzy7gsY595VNoKcQMxGqd7kcc0bFvPpd55HRYUfvrOR5QRiNgo17Gvjzv/axQcuPJPP/O55fnLbCsLXs2aj0K0P7GBy1Tg+eflyJw8rGCcQs1FmS/NhNjy9lw+/aQk1k6vSDsdGMScQs1HmC/fvYPrE8Xz0zUvSDsVGOScQs1HkiV8f4qFt+/mjS5b6QUErOCcQs1Hk7+7bzqwpVVzzhsVph2JjgBOI2SjxSOMBHt15kD99y9lMqnIHSys8JxCzUSAi+Nsfb2fe9Al84ELPvGnF4QRiNgo8tG0/v3r2BT721mUeXdeKxgnErMz19AR//+MdnFkziffULkg7HBtDnEDMytyPtuxla0srH790mWcStKJK9dsm6QpJ2yU1Srq+n+23Snoyee2Q9ELOtu6cbeuLG7lZaYgIbn1gB2efPoXVK+enHY6NMal11ZBUCXwRuAzYA2yStD4itvbWiYi/yKn/MeDVOYc4GhErixWvWSnavq+Nxv3t/J93X0ClB0u0IkvzCmQV0BgROyOiE7gHWH2S+u8H7i5KZGZlYuP2DABvWT475UhsLEozgcwHnstZ35OU/RZJi4AlwEM5xRMk1Ul6TNK7BvoQSdcm9eoymcxIxG1WMh5uyLB8zlTmTZ+Ydig2BpVLi9sa4DsR0Z1TtiiZ5P0DwG2Szupvx4hYFxG1EVE7e7b/SrPRo+N4F5t2HeISX31YStJMIM3Awpz1BUlZf9bQ5/ZVRDQn7zuBn/Ly9hGzUe+xnQfp7O7h4mVOIJaONBPIJmCZpCWSqsgmid/qTSXpXGAG8GhO2QxJ1cnyLOCNwNa++5qNZht3ZJg4vpLaxTPSDsXGqNR6YUVEl6TrgPuASuDOiHhG0k1AXUT0JpM1wD0RETm7rwC+LKmHbBK8Jbf3ltlY8PCODBedNdNPnltqUh1xLSI2ABv6lH26z/pn+9nvEeCCggZnVsJ2H+hg98EjfOiNnvPD0lMujehmluPhhmyPwovPcfuHpccJxKwMPbwjw5k1k1g8c1LaodgY5gRiVmaOd3XzSNNBLjlnNpKfPrf0OIGYlZkndh/iSGc3l/j2laXMCcSszGzckWF8pbjorJlph2JjnBOIWZnZuCND7aIaJld72lpLlxOIWRnZ13qMbXvbPHyJlQQnELMysnFHtvuu2z+sFDiBmJWRh3dkOH1qNefOnZp2KGZOIGblorsn+FnDAS52910rEU4gZmXiqT0vcPjoCd++spLhBGJWJjZuz1AheNPZs9IOxQxwAjErGw83ZHjlgtOYMbkq7VDMACcQs7LwwpFOnnruBd++spLiBGJWBn717Av0BH763EqKE4hZGajf2wrAeWdMSzkSs5ekmkAkXSFpu6RGSdf3s/0aSRlJTyavj+ZsWyupIXmtLW7kZsVV39LG/NMmMm3C+LRDMXtRaoPpSKoEvghcBuwBNkla38/UtPdGxHV99q0BPgPUAgE8kex7qAihmxVdfUsrK+b56sNKS5pXIKuAxojYGRGdwD3A6jz3fTtwf0Q8nySN+4ErChSnWaqOnehmZ6ad8+b56XMrLWkmkPnAcznre5Kyvn5f0mZJ35G0cJD7IulaSXWS6jKZzEjEbVZUDfva6Qk411cgVmJKvRH9P4HFEfFKslcZdw32ABGxLiJqI6J29mx3gbTyU9+SbUD3LSwrNWkmkGZgYc76gqTsRRFxMCKOJ6u3A6/Nd1+z0WJrSyuTqipZVOP5z620pJlANgHLJC2RVAWsAdbnVpA0L2f1KqA+Wb4PuFzSDEkzgMuTMrNRp76lleVzp1JR4QEUrbSk1gsrIrokXUf2F38lcGdEPCPpJqAuItYD/0PSVUAX8DxwTbLv85JuJpuEAG6KiOeL/kOYFVhEsG1vG1deMO/Ulc2KLNU5MSNiA7ChT9mnc5ZvAG4YYN87gTsLGqBZyloOH+Pw0RPugWUlqdQb0c3GNDegWylzAjErYdv2tgGw3DMQWglyAjErYVtbWllYM5GpHsLESpATiFkJq29pZcVc376y0uQEYlaijnZ2s/tAh9s/rGQ5gZiVqB372ugJWOEeWFainEDMSpR7YFmpcwIxK1H1La1Mrqpk4QwPYWKlyQnErETVt7R5CBMraU4gZiUoIqjf60mkrLQ5gZiVoOYXjtJ2rMsJxEqaE4hZCapvyT6B7gRipcwJxKwEbUt6YHkIEytlTiBmJah+byuLZk5iSnWqA2abnZQTiFkJqm9p8xAmVvJSTSCSrpC0XVKjpOv72f4JSVslbZb0oKRFOdu6JT2ZvNb33desXB3p7GL3wQ7O9RPoVuJSuz6WVAl8EbgM2ANskrQ+IrbmVPsVUBsRRyT9CfA3wPuSbUcjYmVRgzYrgu1724hwA7qVvjSvQFYBjRGxMyI6gXuA1bkVIuInEXEkWX0MWFDkGM2KrrcH1nlOIFbi0kwg84Hnctb3JGUD+Qjwo5z1CZLqJD0m6V0D7STp2qReXSaTGV7EZkVQ39LKlOpxLJgxMe1QzE6qLLp4SPogUAtcklO8KCKaJS0FHpL0dEQ09d03ItYB6wBqa2ujKAGbDUN9Syvnzp2K5CFMrLSleQXSDCzMWV+QlL2MpEuBG4GrIuJ4b3lENCfvO4GfAq8uZLBmxRARbNvb5vYPKwtpJpBNwDJJSyRVAWuAl/WmkvRq4Mtkk8f+nPIZkqqT5VnAG4HcxnezsrTn0FHaj3sIEysPqd3CioguSdcB9wGVwJ0R8Yykm4C6iFgP/C0wBfh2cjn/bERcBawAviyph2wSvKVP7y2zsrQ1eQLdXXitHKTaBhIRG4ANfco+nbN86QD7PQJcUNjozIqvYV+2B9byOU4gVvr8JLpZCWnKdHDG9AlM9hAmVgacQMxKSFOmnbNOn5J2GGZ5cQIxKxERQdP+ds6a7QRi5cEJxKxE7Gs9TkdnN2fNnpx2KGZ5cQIxKxFNmXYAX4FY2cgrgUj683zKzGzoXkwgbgOxMpHvFcjafsquGcE4zMa8pv3tTKkex+lTq9MOxSwvJ+0rKOn9wAeAJX3m3JgKPF/IwMzGmqZMB2fNnuwxsKxsnKqz+SNACzAL+Puc8jZgc6GCMhuLmjLtXLR0ZtphmOXtpAkkIn4N/Bq4qDjhmI1N7ce7aDl8zO0fVlbyetxVUhvQOxR6FTAe6IgIj/hmNgJ2ZToA3IXXykpeCSQiXhyYR9kbtKuB1xcqKLOxxl14rRwN+jmQyPoP4O0FiMdsTGrKtFNZIc6cOSntUMzylu8trHfnrFaQnR3wWEEiMhuDmjLtnFkziepxlWmHYpa3fIf8/N2c5S5gN9nbWGY2Apr2d7B0lts/rLzk2wbyoUIHYjZWdfcEuw52cMny2WmHYjYo+Q5lslTSf0rKSNov6fuSlg73wyVdIWm7pEZJ1/ezvVrSvcn2xyUtztl2Q1K+XZLbY6xsNR86SmdXj3tgWdnJtxH934BvAfOAM4BvA3cP54MlVQJfBN4BnAe8X9J5fap9BDgUEWcDtwKfT/Y9j+wc6q8ArgD+OTmeWdlxDywrV/kmkEkR8fWI6Epe3wAmDPOzVwGNEbEzIjqBe/jtdpXVwF3J8neAt+V0I74nIo5HxC6gMTmeWdlxArFylW8C+ZGk6yUtlrRI0l8BGyTVSKoZ4mfPB57LWd+TlPVbJyK6gMPAzDz3BUDStZLqJNVlMpkhhmpWOE2ZdmomVzFjclXaoZgNSr69sN6bvP9Rn/I1ZJ9QH3Z7SKFExDpgHUBtbW2corpZ0TXt73D7h5WlfBPIioh42XMfkib0LRukZmBhzvqCpKy/OnskjQOmAwfz3NesLDRl2rnsvDlph2E2aPnewnokz7LB2AQsk7REUhXZq5n1feqs56W5SK4GHoqISMrXJL20lgDLgF8MMx6zojvU0cnBjk63f1hZOtV8IHPJti1MlPRqoHeigmnAsMZciIguSdcB9wGVwJ0R8Yykm4C6iFgP3AF8XVIj2flH1iT7PiPpW8BWsg82/llEdA8nHrM07DzQOwuhb2FZ+TnVLay3k515cAHwhZzyNuB/DffDI2IDsKFP2adzlo8B7xlg388BnxtuDGZpatrfOwqvr0Cs/JxqPpC7gLsk/X5E/HuRYjIbM5oy7VRVVrBghgdRtPKTbyP6+ZJe0bcwIm4a4XjMxpSmTDtLZk2mssLT2Fr5ybcRvR3oSF7dZJ8eX1ygmMzGjKZMh9s/rGzlO5hi7nzoSPo7so3fZjZEx7u6efb5I7zzlfPSDsVsSAY9oVRiEtmGdTMbomcPHqG7J9yAbmUr3wmlnualOdErgNOBmwsVlNlY4DGwrNzl24j+TmAG8GbgNGBDRDxRsKjMxoCmTLYL71IPY2JlKt9bWKuBrwOzgPHAVyR9rGBRmY0BTfvbmTd9ApOr8/07zqy05PvN/Sjw+ojoAJD0eeBR4J8KFZjZaNeUafftKytr+V6BiGz33V7dvDSsiZkNUkRku/D69pWVsXyvQL4CPC7pe8n6u8iOU2VmQ7C/7Tjtx7s463RfgVj5yvc5kC9I+inwpqToQxHxq4JFZTbKNe13Dywrf3m33kXEL4FfFjAWszGjtwuve2BZORvqg4RmNgxNmQ4mVVUyd9qEtEMxGzInELMUbN/bxrLTpyC5L4qVLycQsyKLCOr3trJi3rS0QzEbllQSiKQaSfdLakjeZ/RTZ6WkRyU9I2mzpPflbPuqpF2SnkxeK4v7E5gN3d7WY7xw5IQTiJW9tK5ArgcejIhlwIPJel9HgD+MiFcAVwC3STotZ/tfRsTK5PVk4UM2GxnbWtoAnECs7KWVQFYDdyXLd5F9ruRlImJHRDQky78B9gOzixahWYFsbWkF4Nx5U1OOxGx40kogcyKiJVneC8w5WWVJq4AqoCmn+HPJra1bJVWfZN9rJdVJqstkMsMO3Gy46ltamX/aRKZNGJ92KGbDUrAEIukBSVv6ea3OrRcRwUtDxfd3nHlkB3L8UET0JMU3AOcCrwNqgE8NtH9ErIuI2oionT3bFzCWvm1723z7ykaFgg0DGhGXDrRN0j5J8yKiJUkQ+weoNw34IXBjRDyWc+zeq5fjkr4CfHIEQzcrmGMnutmZaefK8+emHYrZsKV1C2s9sDZZXgt8v28FSVXA94CvRcR3+mybl7yLbPvJloJGazZCduxroyfcgG6jQ1oJ5BbgMkkNwKXJOpJqJd2e1HkvcDFwTT/ddb+ZzJL4NNk5Sv66uOGbDU39iw3oTiBW/lKZySYiDgJv66e8juzcI0TEN4BvDLD/WwsaoFmB1Le0MamqkkU1k9IOxWzY/CS6WRHVt7SyfO5UKio8hImVPycQsyKJCOpbPISJjR5OIGZF0nL4GK3Hulgx1w8Q2ujgBGJWJL0N6L4CsdHCCcSsSHoTyHJfgdgo4QRiViT1LW0srJnIVA9hYqOEE4hZkdTvbWXFXN++stHDCcSsCI52drP7QIfbP2xUcQIxK4LtHsLERiEnELMi2PZiDyw3oNvo4QRiVgT1La1Mrqpk4QwPYWKjhxOIWRHUt7Rx7rxpHsLERhUnELMCi4hsDyzfvrJRxgnErMCaXzhK27EuznUXXhtlnEDMCqy+pQ1wDywbfVJJIJJqJN0vqSF5nzFAve6cyaTW55QvkfS4pEZJ9yazF5qVpBcnkfIQJjbKpHUFcj3wYEQsAx5M1vtzNCJWJq+rcso/D9waEWcDh4CPFDZcs6HbtreVRTMnMbk6lfnbzAomrQSyGrgrWb6L7LzmeUnmQX8r0DtP+qD2Nyu2+pY2D2Fio1JaCWRORLQky3uBOQPUmyCpTtJjknqTxEzghYjoStb3APMH+iBJ1ybHqMtkMiMSvFm+jnR2sfughzCx0alg19SSHgDm9rPpxtyViAhJMcBhFkVEs6SlwEOSngYODyaOiFgHrAOora0d6HPMCmL73jYi/AS6jU4FSyARcelA2yTtkzQvIlokzQP2D3CM5uR9p6SfAq8G/h04TdK45CpkAdA84j+A2QhwDywbzdK6hbUeWJssrwW+37eCpBmSqpPlWcAbga0REcBPgKtPtr9ZKahvaWVq9TgWzJiYdihmIy6tBHILcJmkBuDSZB1JtZJuT+qsAOokPUU2YdwSEVuTbZ8CPiGpkWybyB1Fjd4sT/UtrZw7byrZvh9mo0sq/Qoj4iDwtn7K64CPJsuPABcMsP9OYFUhYzQbriOdXWzec5i1b1iUdihmBeEn0c0K5PGdz9PZ3cPF58xOOxSzgnACMSuQjTsyTBhfwesW16QdillBOIGYFcjGHRkuWjqTCeMr0w7FrCCcQMwK4NmDR9h1oMO3r2xUcwIxK4CNDdlRDy5xArFRzAnErAA2bs+wsGYiS2ZNTjsUs4JxAjEbYZ1dPTzadIBLzpnt5z9sVHMCMRthT/z6EB2d3Vy8zLevbHRzAjEbYRt3ZBhXId5w9qy0QzErKCcQsxH28I4MtYtnMMUTSNko5wRiNoL2tx5ja0uru+/amOAEYjaCHm44ALj7ro0NTiBmI2jjjgyzp1Zznuf/sDHACcRshHT3BD9vyPDmZbPcfdfGBCcQsxHydPNhDh054dtXNmY4gZiNkI3bM0jwZj//YWNEKglEUo2k+yU1JO8z+qnzO5KezHkdk/SuZNtXJe3K2bay+D+F2cs93JDhlQtOo2ZyVdqhmBVFWlcg1wMPRsQy4MFk/WUi4icRsTIiVgJvBY4AP86p8pe92yPiyaJEbTaAw0dO8KtnD3HJMj88aGNHWglkNXBXsnwX8K5T1L8a+FFEHCloVGZD9PPGA/QEXLLct69s7EgrgcyJiJZkeS8w5xT11wB39yn7nKTNkm6VVD3QjpKulVQnqS6TyQwjZLOBbdyxn2kTxvGqBaelHYpZ0RQsgUh6QNKWfl6rc+tFRABxkuPMAy4A7sspvgE4F3gdUAN8aqD9I2JdRNRGRO3s2f7r0EZeRPDwjgO8adksxlW6X4qNHQUbrCciLh1om6R9kuZFREuSIPaf5FDvBb4XESdyjt179XJc0leAT45I0GZD8OOt+9jbeozLz5ubdihmRZXWn0vrgbXJ8lrg+yep+3763L5Kkg7KPq31LmBLAWI0O6XunuALP97B0lmTeecr56UdjllRpZVAbgEuk9QAXJqsI6lW0u29lSQtBhYCG/vs/01JTwNPA7OAvy5CzGa/5Qebf8P2fW18/LJzfPvKxpxUxpuOiIPA2/oprwM+mrO+G5jfT723FjI+s3x0dfdw2wMNnDt3Ku+8wFcfNvb4TyazIfruL5vZdaCDT1x2DhUVHvvKxh4nELMhON7VzT882MCrFp7GZeedqhe62ejkBGI2BPdueo7mF47yycvP8ci7NmY5gZgN0tHObv7poUZWLanhTZ733MYwJxCzQfrao7vJtB3nk5cv99WHjWlOIGaD0HbsBF/a2MTF58xm1ZKatMMxS5UTiNkg3Pnz3Rw6coJPXn5O2qGYpc4JxCxPmbbj3P6znbz9FXN4pQdNNHMCMctHy+GjvG/do5zo6eF/Xr487XDMSkIqT6KblZPdBzr477c/TuvRE3ztwxdyzpypaYdkVhKcQMxOYtveVj54+y/oieDua1/P+fOnpx2SWclwAjEbwK+ePcQ1X9nExPGVfOOjF3L26b7yMMvlBGLWj0eaDvDRu+qYPbWab3zkQhbWTEo7JLOS4wRiluOFI5382y+e5bYHGlg8cxLf+MiFnD5tQtphmZUkJxAzoGFfG195ZDff/eUejp3o4ZJzZnPb+1YyY3JV2qGZlSwnEBuzenqCjTsy3Plfu/hZwwGqxlXweyvnc80bF7Ni3rS0wzMreakkEEnvAT4LrABWJRNJ9VfvCuAfgErg9ojonblwCXAPMBN4AviDiOgsQuhWpnp6gt0HO3i6+TDP/KaVLc2H2dJ8mNZjXcyZVs1fvn057191JjW+4jDLW1pXIFuAdwNfHqiCpErgi8BlwB5gk6T1EbEV+Dxwa0TcI+lLwEeAfyl82Ja27p7gRHcPx0/0cOREF0c7uzl6optjJ7o50tnN8x2dHGjv5GD7cQ62d3Kg/TgH2o/TuL+djs5uAKrGVbBi7lTe+aozuGjpTK44fy7jPR2t2aClNaVtPXCqkUxXAY0RsTOpew+wWlI98FbgA0m9u8hezRQsgdz4vaf5xa7nC3X4oomRPFb0f7Tos9C73ls/gAgIgt5DRGS39wT0JO8RQXcE3d3BiZ4eunuCrp6X9jmVygoxc3IVM6dUM2tKFVe/dgGvmD+d88+YzrI5U5wwzEZAKbeBzAeey1nfA1xI9rbVCxHRlVP+W/Om95J0LXAtwJlnnjmkQM44bSLL5kwZ0r6lRozg8OMDHKq3uPcPhJfWX9ouJZEkZZUSFRIVFdltFYIKiXEVFYyrFOMqsq/KZH3i+EomVlUycXwlE3KWayaPZ+bkaqZPHO9pZs0KrGAJRNIDwNx+Nt0YEd8v1Of2FRHrgHUAtbW1Q/oj/M9+5+wRjcnMbDQoWAKJiEuHeYhmYGHO+oKk7CBwmqRxyVVIb7mZmRVRKd8I3gQsk7REUhWwBlgf2ZvpPwGuTuqtBYp2RWNmZlmpJBBJvydpD3AR8ENJ9yXlZ0jaAJBcXVwH3AfUA9+KiGeSQ3wK+ISkRrJtIncU+2cwMxvrNFBvmtGotrY26ur6feTEzMwGIOmJiKjtW17Kt7DMzKyEOYGYmdmQOIGYmdmQOIGYmdmQjKlGdEkZ4NdD3H0WcGAEwxkpjmtwHNfgOK7BGa1xLYqI2X0Lx1QCGQ5Jdf31Qkib4xocxzU4jmtwxlpcvoVlZmZD4gRiZmZD4gSSv3VpBzAAxzU4jmtwHNfgjKm43AZiZmZD4isQMzMbEicQMzMbEieQHJLeI+kZST2Savtsu0FSo6Ttkt4+wP5LJD2e1Ls3GYZ+pGO8V9KTyWu3pCcHqLdb0tNJvYKPICnps5Kac2K7coB6VyTnsFHS9UWI628lbZO0WdL3JJ02QL2inK9T/fySqpN/48bku7S4ULHkfOZCST+RtDX5/v95P3XeIulwzr/vpwsdV/K5J/13UdY/Judrs6TXFCGm5Tnn4UlJrZI+3qdOUc6XpDsl7Ze0JaesRtL9khqS9xkD7Ls2qdMgae2QAogIv5IXsAJYDvwUqM0pPw94CqgGlgBNQGU/+38LWJMsfwn4kwLH+/fApwfYthuYVcRz91ngk6eoU5mcu6VAVXJOzytwXJcD45LlzwOfT+t85fPzA38KfClZXgPcW4R/u3nAa5LlqcCOfuJ6C/CDYn2f8v13Aa4EfkR2cuTXA48XOb5KYC/ZB+2Kfr6Ai4HXAFtyyv4GuD5Zvr6/7zxQA+xM3mckyzMG+/m+AskREfURsb2fTauBeyLieETsAhqBVbkVlJ0A/K3Ad5Kiu4B3FSrW5PPeC9xdqM8ogFVAY0TsjIhO4B6y57ZgIuLHkZ1bBuAxsjNYpiWfn3812e8OZL9Lb1Pv5PIFEhEtEfHLZLmN7Pw78wv5mSNoNfC1yHqM7Gyl84r4+W8DmiJiqCNcDEtEPAw836c49zs00O+htwP3R8TzEXEIuB+4YrCf7wSSn/nAcznre/jt/2AzgRdyfln1V7eKg5UAAAR5SURBVGckvRnYFxENA2wP4MeSnpB0bQHjyHVdchvhzgEum/M5j4X0YbJ/rfanGOcrn5//xTrJd+kw2e9WUSS3zF4NPN7P5oskPSXpR5JeUaSQTvXvkvZ3ag0D/xGXxvkCmBMRLcnyXmBOP3VG5LwVbE70UiXpAWBuP5tujIiSmBo3zxjfz8mvPt4UEc2STgful7Qt+WulIHEB/wLcTPY//M1kb699eDifNxJx9Z4vSTcCXcA3BzjMiJ+vciNpCvDvwMcjorXP5l+SvU3TnrRv/QewrAhhley/S9LGeRVwQz+b0zpfLxMRIalgz2qMuQQSEZcOYbdmYGHO+oKkLNdBspfP45K/HPurMyIxShoHvBt47UmO0Zy875f0PbK3T4b1Hy/fcyfpX4Ef9LMpn/M44nFJugZ4J/C2SG4A93OMET9f/cjn5++tsyf5d55O9rtVUJLGk00e34yI7/bdnptQImKDpH+WNCsiCjpwYB7/LgX5TuXpHcAvI2Jf3w1pna/EPknzIqIluZ23v586zWTbaXotINv2Oyi+hZWf9cCapIfMErJ/Sfwit0Lyi+knwNVJ0VqgUFc0lwLbImJPfxslTZY0tXeZbEPylv7qjpQ+951/b4DP2wQsU7a3WhXZy//1BY7rCuCvgKsi4sgAdYp1vvL5+deT/e5A9rv00EBJb6QkbSx3APUR8YUB6sztbYuRtIrs746CJrY8/13WA3+Y9MZ6PXA45/ZNoQ14FyCN85Uj9zs00O+h+4DLJc1IbjdfnpQNTqF7CZTTi+wvvj3AcWAfcF/OthvJ9qDZDrwjp3wDcEayvJRsYmkEvg1UFyjOrwJ/3KfsDGBDThxPJa9nyN7KKfS5+zrwNLA5+QLP6xtXsn4l2V4+TUWKq5Hsvd4nk9eX+sZVzPPV388P3EQ2wQFMSL47jcl3aWkRztGbyN563Jxznq4E/rj3ewZcl5ybp8h2RnhDEeLq99+lT1wCvpicz6fJ6T1Z4Ngmk00I03PKin6+yCawFuBE8rvrI2TbzB4EGoAHgJqkbi1we86+H06+Z43Ah4by+R7KxMzMhsS3sMzMbEicQMzMbEicQMzMbEicQMzMbEicQMzMbEicQMwKQNIjBTjmYkkfGOnjmg2VE4hZAUTEGwpw2MWAE4iVDCcQswKQ1J68v0XSTyV9R9l5Sb6Z84Tybkl/o+x8F7+QdHZS/lVJV/c9FnAL8OZkfom/KPbPZNaXE4hZ4b0a+DjZeWWWAm/M2XY4Ii4A/i9w2ymOcz3ws4hYGRG3FiRSs0FwAjErvF9ExJ6I6CE7TMjinG1357xfVOzAzIbDCcSs8I7nLHfz8lGwo5/lLpL/m5IqyM5eaFZynEDM0vW+nPdHk+XdvDRU/1XA+GS5jeyUs2YlYczNB2JWYmZI2kz2KuX9Sdm/At+X9BTw/4COpHwz0J2Uf9XtIJY2j8ZrlhJJu8kOP16MSYbMRpxvYZmZ2ZD4CsTMzIbEVyBmZjYkTiBmZjYkTiBmZjYkTiBmZjYkTiBmZjYk/x+RJTcEAIkSTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = np.linspace(-10,10)\n",
    "plt.plot(inputs,np.tanh(inputs))\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neuron is just  a linear function (like our linear regression model) within a non-linear function (here tanh). The tanh function limits the output from -1 to 1 and adds non-linearity to our model.\n",
    "\n",
    "See [hyperbolic functions](https://en.wikipedia.org/wiki/Hyperbolic_functions)\n",
    "\n",
    "See [relu function](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A layer of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A layer is just a group of neurons. \n",
    "\n",
    "Each neuron in a layer has its own set of weights and its own bias.\n",
    "\n",
    "The neurons of the layer often have the same inputs, but different weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To code for a layer instead of a single neuron\n",
    "* the 1D weight vector becomes a 2D weight array, one column per neuron\n",
    "* We get one bias term per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "inputData.shape: (1, 15)\n",
      "inputData: [[-1.         -0.85714286 -0.71428571 -0.57142857 -0.42857143 -0.28571429\n",
      "  -0.14285714  0.          0.14285714  0.28571429  0.42857143  0.57142857\n",
      "   0.71428571  0.85714286  1.        ]]\n",
      "************\n",
      "weights.shape: (15, 4)\n",
      "weights: [[-0.11811761 -0.38353495 -0.08457917  0.08341081]\n",
      " [-0.43382017  0.0767557  -0.19239219 -0.30862975]\n",
      " [ 0.09444411  0.09310522 -0.28945619  0.14487115]\n",
      " [-0.2969779  -0.13741122  0.47473021 -0.40367754]\n",
      " [ 0.10170151 -0.05588464 -0.35817307 -0.02775847]\n",
      " [ 0.14006814  0.23001738  0.33647336 -0.34439344]\n",
      " [-0.44897574 -0.24109715  0.21164353  0.0127347 ]\n",
      " [ 0.23419921  0.07986056  0.10652311  0.16417079]\n",
      " [-0.01556977  0.12272424  0.34636548  0.30229926]\n",
      " [-0.36869062 -0.26857063 -0.4652841  -0.05877852]\n",
      " [-0.26288242  0.25404435  0.29463678  0.32394033]\n",
      " [-0.19798855 -0.46045241 -0.12048272  0.10842069]\n",
      " [ 0.14243167  0.26194524 -0.13801073  0.18050683]\n",
      " [ 0.05454577  0.34004807  0.4703649  -0.45592785]\n",
      " [ 0.08145653 -0.41701019 -0.3527916   0.31586076]]\n",
      "************\n",
      "bias.shape (4,)\n",
      "bias: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inputSize=15\n",
    "nNeurons = 4\n",
    "inputData = np.linspace(-1,1,inputSize).reshape(-1,inputSize) # 2D array as input\n",
    "w = np.random.random(inputSize*nNeurons).reshape(inputSize,nNeurons)-0.5 # numbers weights between -0.5 and 0.5, 2D array matching\n",
    "b = np.ones(nNeurons) # bias terms, one per neuron\n",
    "\n",
    "printInputWeightBias(inputData,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_function(inputData,w,b):\n",
    "    \"\"\"\n",
    "    Operation performed by a single neuron.\n",
    "    \n",
    "    The same function also works for an entire layer\n",
    "    \"\"\"\n",
    "    return np.tanh(inputData@w + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (1, 4)\n",
      "[[0.89944783 0.82445048 0.81369454 0.93515541]]\n"
     ]
    }
   ],
   "source": [
    "outputs = neuron_function(inputData,w,b)\n",
    "print(\"Output shape:\", outputs.shape)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Several layers\n",
    "\n",
    "The output of one layer is passed to the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "[[-1.         -0.85714286 -0.71428571 -0.57142857 -0.42857143 -0.28571429\n",
      "  -0.14285714  0.          0.14285714  0.28571429  0.42857143  0.57142857\n",
      "   0.71428571  0.85714286  1.        ]]\n",
      "Output layer 1\n",
      "[[ 0.88824893  0.53471225  0.02498445  0.91299706 -0.20862436  0.95773188\n",
      "   0.83293508  0.30693525  0.69290208  0.98672235  0.53536524  0.26701874\n",
      "   0.95685515  0.82267501  0.89263865]]\n",
      "Output layer 2\n",
      "[[-0.3830017  -0.44873196  0.77578687  0.30493285  0.53473583  0.57911731\n",
      "   0.53523637  0.64436226  0.2243693   0.39241811  0.95707034  0.98630291\n",
      "   0.10187941  0.53164299  0.0255666 ]]\n"
     ]
    }
   ],
   "source": [
    "inputSize=15\n",
    "nNeurons=15 \n",
    "\n",
    "inputData = np.linspace(-1,1,inputSize).reshape(-1,inputSize) # 1D array as input\n",
    "\n",
    "# layer 1 of 15 neurons\n",
    "w_1 = np.random.random(inputSize*nNeurons).reshape(inputSize,nNeurons)-0.5 # numbers weights between 0 and 1, 1D array matching the size of input\n",
    "b_1 = np.ones(nNeurons) # a bias term \n",
    "\n",
    "# layer 2 of 15 neurons\n",
    "w_2 = np.random.random(inputSize*nNeurons).reshape(inputSize,nNeurons)-0.5 # numbers weights between 0 and 1, 1D array matching the size of input\n",
    "b_2 = np.ones(nNeurons) # a bias term \n",
    "\n",
    "print(\"Input\")\n",
    "print(inputData)\n",
    "output_layer1 = neuron_function(inputData,w_1,b_1) # takes inputData as input\n",
    "print(\"Output layer 1\")\n",
    "print(output_layer1)\n",
    "output_layer2 = neuron_function(output_layer1,w_2,b_2) #takes output_layer1 as input\n",
    "print(\"Output layer 2\")\n",
    "print(output_layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just wrote the code to generate a 2-layer deep neural network.\n",
    "\n",
    "If you want to build deep neural network, I recommend using a [pytorch](https://pytorch.org/) or [tensorflow](https://www.tensorflow.org/).\n",
    "\n",
    "A good book covering pytorch is [Deep Learning with PyTorch](https://www.manning.com/books/deep-learning-with-pytorch) from Eli Stevens, Luca Antiga and Thomas Viehmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks (CNN)\n",
    "\n",
    "Bate back to 1989 (Yann LeCun). They are great at detecting objects and classifying images. \n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/convolution1.png\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One of the first convolutional neural network.\n",
    "\n",
    "LeCun et al. (1989). Backpropagation applied to handwritten zip code recognition. Neural Computation.\n",
    "\n",
    "Neurons have receptive fields, similar to what is observed in the visual system.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/LeNet5.png\" width=\"1200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks as feature detectors\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/imageNet_features_01.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/imageNet_features_02.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/imageNet_features_03.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/imageNet_features_04.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet competition: 1.3 million images and 1000 classes\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/imageNetResults.png\" width=\"800\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeplabcut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A method for 3D markerless pose estimation\n",
    "* Uses a deep neural network that was pretrained on image classification\n",
    "* Matches human accuracy, but is much faster\n",
    "* Based on open-source technologies (python, tensorflow, etc)\n",
    "* Training with a graphics card or with online services\n",
    "* Very popular (>5000 followers on Twitter)\n",
    "\n",
    "Previous alternative: video recordings with markers on the animal.\n",
    "\n",
    "Deeplabcut is very well documented.\n",
    "\n",
    "https://www.nature.com/articles/s41593-018-0209-y\n",
    "\n",
    "http://www.mackenziemathislab.org/deeplabcut\n",
    "\n",
    "https://www.nature.com/articles/s41596-019-0176-0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../images/dlcOverview.png\"/>\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../images/MathisFigure1.png\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<div>\n",
    "<img src=\"../images/MathisFigure2.png\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "I recommend downloading the deeplabcut repository. It contains jupyter notebooks that can be used as examples. They are located in `DeepLabCut/examples/JUPYTER`. To train your network on Google Colab, look in `DeepLabCut/examples/COLAB`\n",
    "\n",
    "For our purpose, I created 2 notebooks that I saved in dataNeuroMaster/deeplabcut/\n",
    "\n",
    "* Demo_youowndata.ipynb\n",
    "* Colab_yourowndata.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
